{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EyKuN9sbng14"
   },
   "source": [
    "Name: __Arun Singh__\n",
    "\n",
    "Email Id : erarungwl2013@gmail.com\n",
    "\n",
    "Contact Number : +91 7430066111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why I chose this problem?\n",
    "\n",
    "I have never done this kind of stuff, which exites me. This is literally the first model that I am working on the related to image processing with deep learning.\n",
    "\n",
    "#### What I had in my mind to solve the challenge?\n",
    "As the given research paper regarding making meta learning to be more efficient, I understand the problem is the number of iterations that we need to do, for making a model do multiple things, even with the single data point. That is also the case in the N-way one shot learning classification to classify images in the classes, with a single image of them for training the model.\n",
    "Since I don't have any experience, I stick to the paper, and I was trying to understand the relations between the classification task and the meta learning techniques. The given paper describes that, to learn many tasks and perform them efficiently using a single model, we can train the model initially and then fine tune with a single pass of a single task specific data point.\n",
    "What I think is that more efficient approach of the one shot learning classification would be to train the model on the few sets of classes and then we can fine tune the model whenever there is something new comes in. So comparing the two different techniques, it is safe to assume that the task in meta-learning task is the classifying the image to be as its own class. Then the finding different outputs in a specific task would be same as generating the high similarity score for the items of the same class(same Task).\n",
    "\n",
    "To analyse that the above mentioned theory works in a positive way, I was hoping to create a baseline with a simple or the current state of the art methods.\n",
    "\n",
    "Keeping in mind that and my in-experience in this side of deep learning, I though it was better to stick with the simple siamese model for the startes. SO I started with creating a base line with a simple siamese network used for one shot learning as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UxKGW_pFnfEg",
    "outputId": "1c6e9352-f899-4f2b-f7bf-6896ee44d7f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing necessary packages\n",
    "import os\n",
    "import numpy as np\n",
    "import imageio\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform, RandomNormal\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "# from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mujWYPOcnsKb"
   },
   "outputs": [],
   "source": [
    "# data_loader.py handles the data reading and generating a simple python objects containing data\n",
    "from data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "colab_type": "code",
    "id": "zzmKn8E1oP_W",
    "outputId": "16166daa-eeee-4d67-a371-35c27f7b7395"
   },
   "outputs": [],
   "source": [
    "# batch_generator.py has the modules for the managing bactch which is genrating train and test batches for process\n",
    "from batch_generator import BatchManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdWFS9KUoeH9"
   },
   "outputs": [],
   "source": [
    "# It has the model and it's training functions\n",
    "from siamese import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data'\n",
    "loader = DataLoader(data_path)\n",
    "loader.load_data()\n",
    "train_X, train_y, train_alphabets_to_start_end = loader.training_data\n",
    "test_X, test_y, test_alphabets_to_start_end = loader.evaluation_data\n",
    "loader.store_data(path='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7w1WYTqkobQt"
   },
   "outputs": [],
   "source": [
    "root = '.'\n",
    "data_path = os.path.join(root, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 105, 105, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 105, 105, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 4096)         38947648    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4096)         0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            4097        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 38,951,745\n",
      "Trainable params: 38,951,745\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arun/miniconda3/envs/gpu/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "# initializ model\n",
    "model = get_siamese_model((105, 105, 1))\n",
    "optimizer = Adam(lr = 0.00006)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data and evaluation data\n",
    "with open(os.path.join(root, 'training_data.pkl'), 'rb') as readFile:\n",
    "    training_data = pickle.load(readFile)\n",
    "\n",
    "with open(os.path.join(root, 'evaluation_data.pkl'), 'rb') as readFile:\n",
    "    evaluation_data = pickle.load(readFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_manager = BatchManager(training_data)\n",
    "evaluating_manager = BatchManager(evaluation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_frequency = 10\n",
    "batch_size = 30\n",
    "n_iter = 100\n",
    "N = 20\n",
    "total_number_of_validation_task = 100\n",
    "best = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] Time for 10 iterations: 1.290677539507548 mins\n",
      "train loss: 6.0911030769348145\n",
      "Accuracy: 25.0%  - 20 way one shot learning\n",
      "current best: 25.0, previous best: -1\n",
      "[20] Time for 20 iterations: 4.111621181170146 mins\n",
      "train loss: 5.705084323883057\n",
      "Accuracy: 35.0%  - 20 way one shot learning\n",
      "current best: 35.0, previous best: 25.0\n",
      "[30] Time for 30 iterations: 7.093730219205221 mins\n",
      "train loss: 5.333745956420898\n",
      "Accuracy: 37.0%  - 20 way one shot learning\n",
      "current best: 37.0, previous best: 35.0\n",
      "[40] Time for 40 iterations: 9.888330284754435 mins\n",
      "train loss: 4.982854843139648\n",
      "Accuracy: 34.0%  - 20 way one shot learning\n",
      "[50] Time for 50 iterations: 12.428595920403799 mins\n",
      "train loss: 4.653891086578369\n",
      "Accuracy: 30.0%  - 20 way one shot learning\n",
      "[60] Time for 60 iterations: 15.261238209406535 mins\n",
      "train loss: 4.346142768859863\n",
      "Accuracy: 35.0%  - 20 way one shot learning\n",
      "[70] Time for 70 iterations: 17.516708755493163 mins\n",
      "train loss: 4.060657978057861\n",
      "Accuracy: 32.0%  - 20 way one shot learning\n",
      "[80] Time for 80 iterations: 19.737819810708363 mins\n",
      "train loss: 3.7952866554260254\n",
      "Accuracy: 38.0%  - 20 way one shot learning\n",
      "current best: 38.0, previous best: 37.0\n",
      "[90] Time for 90 iterations: 22.481625739733378 mins\n",
      "train loss: 3.5488204956054688\n",
      "Accuracy: 31.0%  - 20 way one shot learning\n",
      "[100] Time for 100 iterations: 25.086316990852357 mins\n",
      "train loss: 3.3201968669891357\n",
      "Accuracy: 38.0%  - 20 way one shot learning\n",
      "current best: 38.0, previous best: 38.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "for i in range(1, n_iter+1):\n",
    "    (inputs, targets) = training_manager.get_batch(batch_size)\n",
    "    loss = model.train_on_batch(inputs, targets)\n",
    "    if i % evaluation_frequency == 0:\n",
    "        print('[{}] Time for {} iterations: {} mins'.format(i, i, (time.time() - start)/60))\n",
    "        print('train loss: {}'.format(loss))\n",
    "        accuracy = test_model(model,evaluating_manager, N, total_number_of_validation_task, batch_size=20, verbose=False)\n",
    "        model.save_weights(os.path.join(root, 'weights.{}.h5'.format(i)))\n",
    "        if accuracy >= best:\n",
    "            print('current best: {}, previous best: {}'.format(accuracy, best))\n",
    "            best = accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 0.0%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 50.0%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 33.333333333333336%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 25.0%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 40.0%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 33.333333333333336%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 28.571428571428573%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 25.0%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 33.333333333333336%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 30.0%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 27.272727272727273%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 25.0%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 23.076923076923077%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 28.571428571428573%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 26.666666666666668%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 25.0%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 23.529411764705884%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 27.77777777777778%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 26.31578947368421%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 25.0%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 23.80952380952381%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 22.727272727272727%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 21.73913043478261%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 20.833333333333332%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 20.0%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 19.23076923076923%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 18.51851851851852%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 17.857142857142858%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 17.24137931034483%  - 20 way one shot learning\n",
      "Evaluating model on random vevaluation set of batch_size 20, in 20 way classification\n",
      "Evaluating model on validation set with random 20 way one-shot learning tasks...\n",
      "[evaluating] : Accuracy: 16.666666666666668%  - 20 way one shot learning\n",
      "[Evaluating]Accuracy: 16.666666666666668%  - 20 way one shot learning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.666666666666668"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, evaluating_manager, 20, 30, 20, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Becasue of the unavailability of the GPU or high end CPU servers, I couldn't proceed further. I started just a week ago, So I wasn't manage to do much about it, spend days understanding and then creating this much..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I may, I would still like to be considered as a candidate, and I know I would be able to deliver much more than this if I will be given the opportunity.\n",
    "I am strogly motivated by my interests in the field and I am willing to put my time and efforts to the project, and learning that would be require exploring much more where my interest lies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of fellowship.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
