{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fellowship.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPiCDLjELb8tmCUkjNWcbnj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solus9/OSML/blob/master/fellowship.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyKuN9sbng14",
        "colab_type": "text"
      },
      "source": [
        "# FellowShip.AI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxKGW_pFnfEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import imageio\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.engine.topology import Layer\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SwB6JbgorLV",
        "colab_type": "text"
      },
      "source": [
        "#### data_loader.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mujWYPOcnsKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader:\n",
        "\tdef __init__(self, data_path, batch_size=10, image_width=105, image_height=105):\n",
        "\t\tself.data_path = data_path\n",
        "\t\tself.train_paths_dictionary = {}\n",
        "\t\tself.evaluation_paths_dictionary = {}\n",
        "\t\tself.image_width = image_width\n",
        "\t\tself.image_height = image_height\n",
        "\t\tself.batch_size = batch_size\n",
        "\t\tself.training_data = None\n",
        "\t\tself.evaluation_data = None\n",
        "\n",
        "\t\tself.load_data_paths()\n",
        "\n",
        "\tdef load_data_paths(self, ):\n",
        "\t\ttrain_path = os.path.join(self.data_path, 'images_background')\n",
        "\t\tevaluation_path = os.path.join(self.data_path, 'images_evaluation')\n",
        "\n",
        "\t\tfor alphabet in os.listdir(train_path):\n",
        "\t\t\tprint('[Training Data Paths] loading paths : {}'.format(alphabet))\n",
        "\t\t\talphabet_path = os.path.join(train_path, alphabet)\n",
        "\t\t\talphabet_dictionary = {}\n",
        "\t\t\tfor character in os.listdir(alphabet_path):\n",
        "\t\t\t\tcharacter_paths = os.path.join(alphabet_path, character)\n",
        "\t\t\t\talphabet_dictionary[character] = os.listdir(character_paths)\n",
        "\t\t\tself.train_paths_dictionary[alphabet] = alphabet_dictionary\n",
        "\t\t\n",
        "\t\tfor alphabet in os.listdir(evaluation_path):\n",
        "\t\t\tprint('[Evaluation Data Paths] loading paths : {}'.format(alphabet))\n",
        "\t\t\talphabet_path = os.path.join(evaluation_path, alphabet)\n",
        "\t\t\talphabet_dictionary = {}\n",
        "\t\t\tfor character in os.listdir(alphabet_path):\n",
        "\t\t\t\tcharacter_paths = os.path.join(alphabet_path, character)\n",
        "\t\t\t\talphabet_dictionary[character] = os.listdir(character_paths)\n",
        "\t\t\tself.evaluation_paths_dictionary[alphabet] = alphabet_dictionary\n",
        "\n",
        "\tdef load_images(self, train=True):\n",
        "\t\talphabets_to_categories = {}\n",
        "\t\tX = []\n",
        "\t\ty = []\n",
        "\t\t# categories_to_alphabet_character = {}\n",
        "\t\tcurrent_class = 0\n",
        "\t\tpaths_dictionary = self.train_paths_dictionary if train is True else self.evaluation_paths_dictionary\n",
        "\t\tdata_path = os.path.join(self.data_path, 'images_background') if train is True \\\n",
        "\t\t\telse os.path.join(self.data_path, 'images_evaluation')\n",
        "\t\tfor alphabet in paths_dictionary:\n",
        "\t\t\tprint('[{} Data] Loading Images : {}'.format('Training' if train is True else 'Test', alphabet))\n",
        "\t\t\talphabets_to_categories[alphabet] = [current_class, None]\n",
        "\t\t\tfor character in paths_dictionary[alphabet]:\n",
        "\t\t\t\t# categories_to_alphabet_character[current_class] = [alphabet, character]\n",
        "\t\t\t\tcategory_images = []\n",
        "\t\t\t\tfor file in os.listdir(os.path.join(data_path, alphabet, character)):\n",
        "\t\t\t\t\timage = imageio.imread(os.path.join(data_path, alphabet, character, file))\n",
        "\t\t\t\t\tcategory_images.append(image)\n",
        "\t\t\t\t\ty.append(current_class)\n",
        "\t\t\t\ttry:\n",
        "\t\t\t\t\tX.append(np.stack(category_images))\n",
        "\t\t\t\texcept ValueError as e:\n",
        "\t\t\t\t\tprint(e)\n",
        "\t\t\t\t\tprint(\"error : catergory images : {}\".format(category_images))\n",
        "\t\t\t\tcurrent_class += 1\n",
        "\t\t\talphabets_to_categories[alphabet][1] = current_class - 1\n",
        "\t\ty = np.vstack(y)\n",
        "\t\tX = np.stack(X)\n",
        "\t\treturn X, y, alphabets_to_categories\n",
        "\n",
        "\tdef load_data(self, ):\n",
        "\t\tself.load_data_paths()\n",
        "\t\tself.training_data = self.load_images()\n",
        "\t\tself.evaluation_data = self.load_images(train=False)\n",
        "\n",
        "\tdef store_data(self, path=None):\n",
        "\t\tif path is None: path = self.data_path\n",
        "\t\twith open(os.path.join(path, 'training_data.pkl'), 'wb') as writeFile:\n",
        "\t\t\tpickle.dump(self.training_data, writeFile)\n",
        "\t\tprint('Training Data written : {}'.format(os.path.join(path, 'training_data.pkl')))\n",
        "\t\twith open(os.path.join(path, 'evaluation_data.pkl'), 'wb') as writeFile:\n",
        "\t\t\tpickle.dump(self.evaluation_data, writeFile)\n",
        "\t\tprint('Evaluation Data written : {}'.format(os.path.join(path, 'evaluation_data.pkl')))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnQtE91-oxpG",
        "colab_type": "text"
      },
      "source": [
        "#### batch_generatory.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzmKn8E1oP_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "b9e07687-3834-478c-922b-0cd95d37a00a"
      },
      "source": [
        "class BatchManager:\n",
        "\tdef __init__(self, loaded_data):\n",
        "\t\tself.width = 105\n",
        "\t\tself.height = 105\n",
        "\t\t(self.X, self.y, self.categories) = loaded_data\n",
        "\t\t\n",
        "\tdef get_batch(self, batch_size=1000):\n",
        "\t\tclasses, items_per_class, width, height = self.X.shape\n",
        "\t\tchosen_categories = np.random.choice(classes, size=(batch_size, ), replace=False)\n",
        "\n",
        "\t\tpairs = [np.zeros((batch_size, width, height, 1)) for _ in range(2)]\n",
        "\n",
        "\t\ttargets = np.zeros((batch_size, ))\n",
        "\t\ttargets[batch_size//2:] = 1\n",
        "\n",
        "\t\tcount = 0\n",
        "\t\tfor category in chosen_categories:\n",
        "\t\t\tchosen_item = np.random.randint(0, items_per_class)\n",
        "\t\t\tpairs[0][count, :, :, :] = self.X[category, chosen_item].reshape(width, height, 1)\n",
        "\t\t\tif count < batch_size // 2:\n",
        "\t\t\t\tcategory = (category + np.random.randint(1, classes)) % classes\n",
        "\t\t\t\tchosen_item = np.random.randint(0, items_per_class)\n",
        "\t\t\telse:\n",
        "\t\t\t\tchosen_item = (chosen_item + np.ranint(1, items_per_class)) % items_per_class\n",
        "\t\t\tpairs[1][count, :, :, :] = self.X[category, chosen_item].reshape(width, height, 1)\n",
        "\t\treturn pairs, targets\n",
        "\n",
        "\tdef generator(self, batch_size):\n",
        "\t\twhile True:\n",
        "\t\t\tpairs, targets = self.get_batch(batch_size)\n",
        "\t\t\tyield (pairs, targets)\n",
        "   \n",
        "  def get_test_batch(self, batch_size):\n",
        "\t\tclasses, items_per_class, width, height = self.X.shape\n",
        "\t\tindices = np.random.randin(0, items_per_class, size=(batch_size, ))\n",
        "\t\tchosen_categories = np.random.choice(range(classes), size=(batch_size, ), replace=False)\n",
        "\t\ttrue_category = chosen_categories[0]\n",
        "\t\titem1, item2 = np.random.choice(items_per_class, size=(2, ), replace=False)\n",
        "\t\t# create N copies for the true category item for evaluation in 'batch_size' way\n",
        "\t\ttest_image = np.asarray([self.X[true_category, item1, : , :]] * batch_size).reshape( \\\n",
        "\t\t\tbatch_size, width, height, 1)\n",
        "\t\tsuuport_images = X[chosen_categories, indices, :, :]\n",
        "\t\tsupport_images[0, :, :] = X[true_category, item2]\n",
        "\t\tsupport_images = support_images.reshape(batch_size, self.width, self.height, 1)\n",
        "\t\ttargets = np.zeros(size(batch_size, ))\n",
        "\t\ttargets[0] = 1\n",
        "\t\ttargets, test_image, support_images = shuffle(targets, test_image, support_images)\n",
        "\t\tpairs = [test_image, support_images]\n",
        "\t\treturn pairs, targets"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-646f2b7efb78>\"\u001b[0;36m, line \u001b[0;32m33\u001b[0m\n\u001b[0;31m    def get_test_batch(self, batch_size):\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gwt-AbYzo1va",
        "colab_type": "text"
      },
      "source": [
        "#### siamese.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdWFS9KUoeH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_weights(shape):\n",
        "\treturn np.random.normal(loc=0.0, scale=1e-2, size=shape)\n",
        "\n",
        "def initialize_bias(shape):\n",
        "\treturn np.random.normal(loc=0.5, scale=1e-2, size=shape)\n",
        "\n",
        "def get_siamese_model(input_shape):\n",
        "\tleft_input = Input(input_shape)\n",
        "\tright_input = Input(input_shape)\n",
        "\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(64, (10, 10), activation='relu', input_shape=input_shape, \\\n",
        "\t\tkernel_initializer=initialize_weights, kernel_regularizer=12(2e-4)))\n",
        "\tmodel.add(MaxPooling2D())\n",
        "\tmodel.add(Conv2D(128, (7, 7), activation='relu', \\\n",
        "\t\tkernel_initializer=initialize_weights, bias_initializer=initialize_bias, \\\n",
        "\t\tkernel_regularizer=12(2e-4)))\n",
        "\tmodel.add(MaxPooling2D())\n",
        "\tmodel.add(Conv2D(128, (4, 4), activation='relu', \\\n",
        "\t\tkernel_initializer=initialize_weights, bias_initializer=initialize_bias, \\\n",
        "\t\tkernel_regularizer=12(2e-4)))\n",
        "\tmodel.add(MaxPooling2D())\n",
        "\tmodel.add(Conv2D(256, (4, 4), activation='relu', \\\n",
        "\t\tkernel_initializer=initialize_weights, bias_initializer=initialize_bias, \\\n",
        "\t\tkernel_regularizer=12(2e-4)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(4096, activation='sigmoid', kernel_regularizer=12(1e-3), \\\n",
        "\t\tkernel_initializer=initialize_weights, bias_initializer=initialize_bias))\n",
        "\tleft_encoded = model(left_input)\n",
        "\tright_encoded = model(right_input)\n",
        "\n",
        "\tL1_layer = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))\n",
        "\tL1_distance = L1_layer([left_encoded, right_encoded])\n",
        "\n",
        "\tprediction = Dense(1, activation='sigmoid', bias_initializer=initialize_bias)(L1_distance)\n",
        "\tsiamese_network = Model(inputs=[left_input, right_input], output=prediction)\n",
        "\treturn siamese_network\n",
        "\n",
        "def test_oneshot_once(model, validataion_data, N, verbose=True):\n",
        "\tpairs, targets = validataion_data\n",
        "\tif targets.shape < N:\n",
        "\t\traise ValueError('supported images are : {} which is less than \\\n",
        "\t\t\tClassification Way: {}'.format(pairs[1].shape, N))\n",
        "\tif verbose:\n",
        "\t\tprint('Evaluating model on validation set with random {} way one-shot learning tasks...'.format(N))\n",
        "\tprobabilities = model.predict(pairs)\n",
        "\tif np.argmax(probabilities) == np.argmax(targets):\n",
        "\t\treturn True\n",
        "\telse: return False"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiuArWujo5G-",
        "colab_type": "text"
      },
      "source": [
        "#### training.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR1GB-CfoiIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}